% Referências Definitivas
@article{Dissanayake2001,
abstract = {The simultaneous localization and map building (SLAM) problem asks$\backslash$nif it is possible for an autonomous vehicle to start in an unknown$\backslash$nlocation in an unknown environment and then to incrementally build a map$\backslash$nof this environment while simultaneously using this map to compute$\backslash$nabsolute vehicle location. Starting from estimation-theoretic$\backslash$nfoundations of this problem, the paper proves that a solution to the$\backslash$nSLAM problem is indeed possible. The underlying structure of the SLAM$\backslash$nproblem is first elucidated. A proof that the estimated map converges$\backslash$nmonotonically to a relative map with zero uncertainty is then developed.$\backslash$nIt is then shown that the absolute accuracy of the map and the vehicle$\backslash$nlocation reach a lower bound defined only by the initial vehicle$\backslash$nuncertainty. Together, these results show that it is possible for an$\backslash$nautonomous vehicle to start in an unknown location in an unknown$\backslash$nenvironment and, using relative observations only, incrementally build a$\backslash$nperfect map of the world and to compute simultaneously a bounded$\backslash$nestimate of vehicle location. The paper also describes a substantial$\backslash$nimplementation of the SLAM algorithm on a vehicle operating in an$\backslash$noutdoor environment using millimeter-wave radar to provide relative map$\backslash$nobservations. This implementation is used to demonstrate how some key$\backslash$nissues such as map management and data association can be handled in a$\backslash$npractical environment. The results obtained are cross-compared with$\backslash$nabsolute locations of the map landmarks obtained by surveying. In$\backslash$nconclusion, the paper discusses a number of key issues raised by the$\backslash$nsolution to the SLAM problem including suboptimal map-building$\backslash$nalgorithms and map management},
author = {Dissanayake, M.W.M.G. and Newman, P. and Clark, S. and Durrant-Whyte, H.F. and Csorba, M.},
doi = {10.1109/70.938381},
isbn = {1042-296X},
issn = {1042-296X},
journal = {IEEE Transactions on Robotics and Automation},
number = {3},
pages = {229--241},
title = {{A solution to the simultaneous localization and map building (SLAM)$\backslash$nproblem}},
volume = {17},
year = {2001}
}

@misc{AAVC,
mendeley-groups = {TCC},
title = {{Autonomous Aerial Vehicle Competition}},
url = {http://www.flyaavc.org/}
}

@article{Lemaire2007,
author = {Lemaire, Thomas and Berger, Cyrille and Jung, Il-Kyun and Lacroix, Simon},
doi = {10.1007/s11263-007-0042-3},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {3D SLAM,bearing only SLAM,interest point matching},
language = {English},
number = {3},
pages = {343--364},
publisher = {Kluwer Academic Publishers-Plenum Publishers},
title = {{Vision-Based SLAM: Stereo and Monocular Approaches}},
url = {http://dx.doi.org/10.1007/s11263-007-0042-3},
volume = {74},
year = {2007}
}

@article{Shah2014,
abstract = {In 2012 a federal mandate was imposed that required the FAA to integrate unmanned aerial systems (UAS) into the national airspace (NAS) by 2015 for civilian and commercial use. A significant driver for the increasing popularity of these systems is the rise in open hardware and open software solutions which allow hobbyists to build small UAS at low cost and without specialist equipment. This paper describes our work building, evaluating and improving performance of a vision-based system running on an embedded computer onboard such a small UAS. This system utilises open source software and open hardware to automatically land a multi-rotor UAS with high accuracy. Using parallel computing techniques, our final implementation runs at the maximum possible rate of 30 frames per second. This demonstrates a valid approach for implementing other real-time vision based systems onboard UAS using low power, small and economical embedded computers.},
author = {Shah, Sunil},
file = {:media/nicolas/Documentos/Google Drive/TCC/Books/Disserta{\c{c}}{\~{o}}es/EECS-2014-117.pdf:pdf},
mendeley-groups = {TCC},
pages = {1--29},
title = {{Real-time Image Processing on Low Cost Embedded Computers}},
year = {2014}
}

@book{Bradski2008,
abstract = {Learning OpenCV puts you right in the middle of the rapidly expanding field of computer vision. Written by the creators of OpenCV, the widely used free open- source library, this book introduces you to computer vision and demonstrates how you can quickly build applications that enable computers to "see" and make decisions based on the data. Computer vision is everywhere - in security systems, manufacturing inspection systems, medical image analysis, Unmanned Aerial Vehicles, and more. It helps robot cars drive by themselves, stitches Google maps and Google Earth together, checks the pixels on your laptop's LCD screen, and makes sure the stitches in your shirt are OK. OpenCV provides an easy-to-use computer vision infrastructure along with a comprehensive library containing more than 500 functions that can run vision code in real time. With Learning OpenCV, any developer or hobbyist can get up and running with the framework quickly, whether it's to build simple or sophisticated vision applications. The book includes: A thorough introduction to OpenCV Getting input from cameras Transforming images Shape matching Pattern recognition, including face detection Segmenting images Tracking and motion in 2 and 3 dimensions Machine learning algorithms Hands-on exercises at the end of each chapter help you absorb the concepts, and an appendix explains how to set up an OpenCV project in Visual Studio. OpenCV is written in performance optimized C/C++ code, runs on Windows, Linux, and Mac OS X, and is free for commercial and research use under a BSD license. Getting machines to see is a challenging but entertaining goal. If you're intrigued by the possibilities, Learning OpenCV gets you started onbuilding computer vision applications of your own.},
author = {Bradski, Gary and Kaehler, Adrian},
booktitle = {OReilly Media Inc},
doi = {10.1109/MRA.2009.933612},
isbn = {0596516134},
issn = {10709932},
mendeley-groups = {TCC},
pages = {555},
title = {{Learning OpenCV: Computer Vision with the OpenCV Library}},
url = {http://www.amazon.com/dp/0596516134},
volume = {1},
year = {2008}
}

@article{ShinzatoP,
author = {{Shinzato, P. Y. ; Os{\'{o}}rio, F. S. ; Wolf}, D. F.},
journal = {IEEE/RSJ International Conference on Intelligent Robots and Systems - IROS - Workshop},
mendeley-groups = {TCC},
title = {{Visual Road Recognition Using Artificial Neural Networks and Stereo Vision.}}
}

@article{BarryMIT,
author = {Barry, Andrew J and Oleynikova, Helen and Honegger, Dominik and Pollefeys, Marc and Tedrake, Russ},
file = {:media/nicolas/Documentos/Google Drive/TCC/Books/Artigos/Richard Szeliski - Computer Vision Algorithms and Applications.pdf:pdf},
journal = {Vision-based Control and Navigation of Small Lightweight UAVs, IROS Workshop},
mendeley-groups = {TCC},
pages = {1--6},
title = {{FPGA vs . Pushbroom Stereo Vision for MAVs}},
year = {2015}
}

@article{Breivik2010,
abstract = {Submarine oil and gas pipeline inspection is a highly time and cost consuming task. Using an autonomous underwater vehicle (AUV) for such applications represents a great saving potential. However, the AUV navigation system requires reliable localization and stable tracking of the pipeline position. We present a method for robust pipeline localization relative to the AUV in 3D based on stereo vision and echo sounder depth data. When the pipe is present in both camera images, a standard stereo vision approach is used for localization. Enhanced localization continuity is ensured using a second approach when the pipe is segmented out in only one of the images. This method is based on a combination of one camera with depth information from the echo sounder mounted on the AUV. In the algorithm, the plane spanned by the pipe in the camera image is intersected with the plane spanned by the sea floor, to give the pipe position in 3D relative to the AUV. Closed water recordings show that the proposed method localizes the pipe with an accuracy comparable to that of the stereo vision method. Furthermore, the introduction of a second pipe localization method increases the true positive pipe localization rate by a factor of four.},
author = {Breivik, G M and Fjerdingen, S A and Skotheim, O},
doi = {Artn 75390b$\backslash$nDoi 10.1117/12.839962},
isbn = {0277-786X},
journal = {Intelligent Robots and Computer Vision Xxvii: Algorithms and Techniques},
keywords = {autonomous underwater vehicle,auv,cable tracker,echo sounder,pipe inspection,robot vision,robust localization,scene analysis,stereo vision},
mendeley-groups = {TCC},
title = {{Robust Pipeline Localization for an Autonomous Underwater Vehicle using Stereo Vision and Echo Sounder Data}},
url = {<Go to ISI>://WOS:000283489200009},
volume = {7539},
year = {2010}
}

% Exemplos - Remover Depois
@misc { referencia1,
		author = "Autor da referência 1.",
		title = "Título da referência 1",
		edition = "Terceira edição",
		year = 2007
}

@misc { referencia2,
	author = "",
	title = "Google",
	howpublished = "\url{http://www.google.com.br/}",
	year = "Acesso em: 04 de dezembro de 2014"
}

