% Referências Definitivas
@article{Dissanayake2001,
abstract = {The simultaneous localization and map building (SLAM) problem asks$\backslash$nif it is possible for an autonomous vehicle to start in an unknown$\backslash$nlocation in an unknown environment and then to incrementally build a map$\backslash$nof this environment while simultaneously using this map to compute$\backslash$nabsolute vehicle location. Starting from estimation-theoretic$\backslash$nfoundations of this problem, the paper proves that a solution to the$\backslash$nSLAM problem is indeed possible. The underlying structure of the SLAM$\backslash$nproblem is first elucidated. A proof that the estimated map converges$\backslash$nmonotonically to a relative map with zero uncertainty is then developed.$\backslash$nIt is then shown that the absolute accuracy of the map and the vehicle$\backslash$nlocation reach a lower bound defined only by the initial vehicle$\backslash$nuncertainty. Together, these results show that it is possible for an$\backslash$nautonomous vehicle to start in an unknown location in an unknown$\backslash$nenvironment and, using relative observations only, incrementally build a$\backslash$nperfect map of the world and to compute simultaneously a bounded$\backslash$nestimate of vehicle location. The paper also describes a substantial$\backslash$nimplementation of the SLAM algorithm on a vehicle operating in an$\backslash$noutdoor environment using millimeter-wave radar to provide relative map$\backslash$nobservations. This implementation is used to demonstrate how some key$\backslash$nissues such as map management and data association can be handled in a$\backslash$npractical environment. The results obtained are cross-compared with$\backslash$nabsolute locations of the map landmarks obtained by surveying. In$\backslash$nconclusion, the paper discusses a number of key issues raised by the$\backslash$nsolution to the SLAM problem including suboptimal map-building$\backslash$nalgorithms and map management},
author = {Dissanayake, M.W.M.G. and Newman, P. and Clark, S. and Durrant-Whyte, H.F. and Csorba, M.},
doi = {10.1109/70.938381},
isbn = {1042-296X},
issn = {1042-296X},
journal = {IEEE Transactions on Robotics and Automation},
number = {3},
pages = {229--241},
title = {{A solution to the simultaneous localization and map building (SLAM)$\backslash$nproblem}},
volume = {17},
year = {2001}
}

@misc{AAVC,
mendeley-groups = {TCC},
title = {{FLYAAVC. Autonomous Aerial Vehicle Competition}},
url = {http://www.flyaavc.org/},
howpublished={\url{http://www.flyaavc.org/}},
year=2015
}

@article{Lemaire2007,
author = {Lemaire, Thomas and Berger, Cyrille and Jung, Il-Kyun and Lacroix, Simon},
doi = {10.1007/s11263-007-0042-3},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {3D SLAM,bearing only SLAM,interest point matching},
language = {English},
number = {3},
pages = {343--364},
publisher = {Kluwer Academic Publishers-Plenum Publishers},
title = {{Vision-Based SLAM: Stereo and Monocular Approaches}},
url = {http://dx.doi.org/10.1007/s11263-007-0042-3},
volume = {74},
year = {2007}
}

@article{Shah2014,
abstract = {In 2012 a federal mandate was imposed that required the FAA to integrate unmanned aerial systems (UAS) into the national airspace (NAS) by 2015 for civilian and commercial use. A significant driver for the increasing popularity of these systems is the rise in open hardware and open software solutions which allow hobbyists to build small UAS at low cost and without specialist equipment. This paper describes our work building, evaluating and improving performance of a vision-based system running on an embedded computer onboard such a small UAS. This system utilises open source software and open hardware to automatically land a multi-rotor UAS with high accuracy. Using parallel computing techniques, our final implementation runs at the maximum possible rate of 30 frames per second. This demonstrates a valid approach for implementing other real-time vision based systems onboard UAS using low power, small and economical embedded computers.},
author = {Shah, Sunil},
file = {:media/nicolas/Documentos/Google Drive/TCC/Books/Disserta{\c{c}}{\~{o}}es/EECS-2014-117.pdf:pdf},
mendeley-groups = {TCC},
pages = {1--29},
title = {{Real-time Image Processing on Low Cost Embedded Computers}},
year = {2014}
}

@book{Bradski2008,
abstract = {Learning OpenCV puts you right in the middle of the rapidly expanding field of computer vision. Written by the creators of OpenCV, the widely used free open- source library, this book introduces you to computer vision and demonstrates how you can quickly build applications that enable computers to "see" and make decisions based on the data. Computer vision is everywhere - in security systems, manufacturing inspection systems, medical image analysis, Unmanned Aerial Vehicles, and more. It helps robot cars drive by themselves, stitches Google maps and Google Earth together, checks the pixels on your laptop's LCD screen, and makes sure the stitches in your shirt are OK. OpenCV provides an easy-to-use computer vision infrastructure along with a comprehensive library containing more than 500 functions that can run vision code in real time. With Learning OpenCV, any developer or hobbyist can get up and running with the framework quickly, whether it's to build simple or sophisticated vision applications. The book includes: A thorough introduction to OpenCV Getting input from cameras Transforming images Shape matching Pattern recognition, including face detection Segmenting images Tracking and motion in 2 and 3 dimensions Machine learning algorithms Hands-on exercises at the end of each chapter help you absorb the concepts, and an appendix explains how to set up an OpenCV project in Visual Studio. OpenCV is written in performance optimized C/C++ code, runs on Windows, Linux, and Mac OS X, and is free for commercial and research use under a BSD license. Getting machines to see is a challenging but entertaining goal. If you're intrigued by the possibilities, Learning OpenCV gets you started onbuilding computer vision applications of your own.},
author = {Bradski, Gary and Kaehler, Adrian},
booktitle = {OReilly Media Inc},
doi = {10.1109/MRA.2009.933612},
isbn = {0596516134},
issn = {10709932},
mendeley-groups = {TCC},
pages = {555},
title = {{Learning OpenCV: Computer Vision with the OpenCV Library}},
url = {http://www.amazon.com/dp/0596516134},
volume = {1},
year = {2008}
}

@article{ShinzatoP,
author = {{Shinzato, P. Y. ; Os{\'{o}}rio, F. S. ; Wolf}, D. F.},
journal = {IEEE/RSJ International Conference on Intelligent Robots and Systems - IROS - Workshop},
mendeley-groups = {TCC},
title = {{Visual Road Recognition Using Artificial Neural Networks and Stereo Vision.}}
}

@article{BarryMIT,
author = {Barry, Andrew J and Oleynikova, Helen and Honegger, Dominik and Pollefeys, Marc and Tedrake, Russ},
file = {:media/nicolas/Documentos/Google Drive/TCC/Books/Artigos/Richard Szeliski - Computer Vision Algorithms and Applications.pdf:pdf},
journal = {Vision-based Control and Navigation of Small Lightweight UAVs, IROS Workshop},
mendeley-groups = {TCC},
pages = {1--6},
title = {{FPGA vs . Pushbroom Stereo Vision for MAVs}},
year = {2015}
}

@article{Nagappa2013,
abstract = {This paper considers the application of feature- based simultaneous localisation and mapping (SLAM) using a random finite sets (RFS) framework for an autonomous underwater vehicle. SLAM allows for reduction in localisation error by tracking features which provide a fixed external reference. The SLAM problem is addressed here using a single- cluster probability hypothesis density (PHD) filter. The filter uses a particle approximation for the vehicle position with a conditional Gaussian mixture PHD for the feature map. Map features are selected as unique point features generated from a stereo camera on-board the vehicle. We demonstrate the improvement in localisation applying the algorithm to a dataset obtained in an indoor test tank. I.},
author = {Nagappa, Sharad and Palomeras, Narc{\'{\i}}s and Lee, Chee Sing and Gracias, Nuno and Clark, Daniel E. and Salvi, Joaquim},
doi = {10.1109/OCEANS-Bergen.2013.6608107},
file = {:media/nicolas/Documentos/Google Drive/TCC/Books/Artigos/Nagappa13{\_}oceans{\_}130118-113.pdf:pdf},
isbn = {978-1-4799-0001-5},
journal = {2013 MTS/IEEE OCEANS-Bergen},
keywords = {SLAM,underwater,vision},
mendeley-groups = {TCC},
number = {Ref 288273},
pages = {1--9},
title = {{Single cluster PHD SLAM: Application to autonomous underwater vehicles using stereo vision}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6608107},
year = {2013}
}

@misc{UEDA2011,
author = {UEDA, Etsuko; and Koeda, Masanao; and Suenaga, Tsuyoshi; and Takemura, Kentaro;},
booktitle = {Jan 05, 2011},
mendeley-groups = {TCC},
title = {{3D Reconstruction and Point Cloud Rendering}},
url = {http://opencv.jp/opencv2-x-samples/point-cloud-rendering},
urldate = {Dec 5, 2015},
year = {2011}
}

@misc{Hounslow2013,
author = {Hounslow, Kyle},
booktitle = {Mar 11, 2013},
mendeley-groups = {TCC},
title = {{Real-Time Object Tracking Using OpenCV}},
url = {https://raw.githubusercontent.com/kylehounslow/opencv-tuts/master/object-tracking-tut/objectTrackingTut.cpp https://www.youtube.com/watch?v=bSeFrPrqZ2A},
urldate = {2015-12-05},
year = {2013}
}

@misc{NVIDIA,
author = {NVIDIA},
mendeley-groups = {TCC},
title = {CUDA - Plataforma Paralela de Computação},
url = {http://www.nvidia.com.br/object/cuda{\_}home{\_}new{\_}br.html{\#}axzz41r8CUrUY},
howpublished={\url{http://www.nvidia.com.br/object/cuda_home_new_br.html}},
urldate = {2015-03-03},
year = {2016}
}

@article{Filho2014,
author = {Filho, Jos{\'{e}} Luiz Boanova},
journal = {Revista Brasileira de Direito Aeron{\'{a}}utico e Espacial},
mendeley-groups = {TCC},
title = {{Aeronaves N{\~{a}}o Tripul{\'{a}}veis no Brasil e sua Regula{\c{c}}{\~{a}}o}},
url = {http://www.sbda.org.br/revista/1868.pdf},
year = {2014}
}

@misc{DECEA2015,
author = {{Departamento de Controle do Espa{\c{c}}o A{\'{e}}reo da Aeron{\'{a}}utica}},
booktitle = {Nov 27,2015},
mendeley-groups = {TCC},
title = {{DECEA publica nova regulamenta{\c{c}}{\~{a}}o para voos de RPAS (drones)}},
url = {http://www.decea.gov.br/?p=8465},
urldate = {Dec 6, 2015},
year = {2015}
}

@misc{eLinuxJetsonOpenCV,
author = {Wiki, Embedded Linux},
keywords = {CUDA,GPU,Jetson TK1,OpenCV},
mendeley-groups = {TCC},
title = {{Installing OpenCV (including the GPU module) on Jetson TK1}},
url = {http://elinux.org/Jetson/Installing{\_}OpenCV},
howpublished={\url{http://elinux.org/Jetson/Installing_OpenCV}},
urldate = {2016-03-16}
}

@phdthesis{Mendes2012,
author = {Mendes, Caio C{\'{e}}sar Teodoro},
file = {:home/nicolas/Desktop/dissertacao{\_}rev{\_}a4-caio.pdf:pdf},
mendeley-groups = {TCC},
school = {University of S{\~{a}}o Paulo},
title = {{Navega{\c{c}}{\~{a}}o de rob{\^{o}}s m{\'{o}}veis utilizando vis{\~{a}}o est{\'{e}}reo}},
year = {2012}
}

@book{RobertLaganiere,
  Author = {Robert Laganière},
  Title = {OpenCV 2 Computer Vision Application Programming Cookbook},
  Publisher = {Packt Publishing},
  Year = {2011},
  ISBN = {1849513244},
  URL = {http://www.amazon.com/OpenCV-Computer-Application-Programming-Cookbook/dp/1849513244%3FSubscriptionId%3D0JYN1NVW651KCA56C102%26tag%3Dtechkie-20%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3D1849513244}
}

@misc{DevelopmentTeam2016,
author = {{Development Team}, OpenCV},
booktitle = {OpenCV 2.4.12.0 documentation},
mendeley-groups = {TCC},
title = {{Camera Calibration and 3D Reconstruction}},
url = {http://docs.opencv.org/2.4/modules/calib3d/doc/camera{\_}calibration{\_}and{\_}3d{\_}reconstruction.html},
howpublished={\url{http://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html}},
urldate = {2016-03-30},
year = {2014}
}

